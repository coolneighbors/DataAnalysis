import datetime
import os
import pickle
import warnings
from copy import copy

import astropy
import numpy as np
import pandas
import pandas as pd
import webbrowser
import matplotlib.pyplot as plt
from astropy.coordinates import SkyCoord
import astropy.units as u
from astroquery.simbad import Simbad
import functools
from unWISE_verse.Spout import Spout

from Checker import SIMBADChecker


class Analyzer:
    def __init__(self, extracted_file, reduced_file, save_login=True):
        """
        Initializes an Analyzer object, which is used to analyze the extracted and reduced classifications from a
        Zooniverse project.

        Parameters
        ----------
            extracted_file : str
                The path to the extracted classifications file, generated by the Classifier class.
            reduced_file : str
                The path to the reduced classifications file, generated by the Classifier class.
            save_login : bool
                Whether or not to save the login information to a file, including Zooniverse IDs. Default is True.
        Notes
        -----
        This class is used to analyze the extracted and reduced classifications from a Zooniverse project.
        The extracted classifications file is a CSV file containing all of the classifications made by all users.
        The reduced classifications file is a CSV file containing the reduced classifications for each subject.
        """
        
        # Initialize variables
        self.extracted_file = extracted_file
        self.reduced_file = reduced_file
        self.extracted_dataframe = pd.read_csv(self.extracted_file)
        self.reduced_dataframe = pd.read_csv(self.reduced_file)
        self.subject_set_id = None
        self.login(save_login)

    def login(self, save=True):
        """
        Logs into Zooniverse using Spout and saves the login information and Zooniverse IDs each to a file.

        Parameters
        ----------
        save : bool
            Whether or not to save the login information to a file, including Zooniverse IDs. Default is True.

        Notes
        -----
        This method is called by the __init__ method automatically. If you want to login to a different
        Zooniverse account, delete the login.pickle file. If you want to login to the same account,
        but with different Zooniverse IDs, delete the zooniverse_ids2.pickle file.
        """

        # Get login
        login = Spout.requestLogin(save=save)

        # Get Zooniverse IDs
        project_id, self.subject_set_id = Spout.requestZooniverseIDs(save=save)

        # Create Spout object to access the Zooniverse project
        Spout(project_identifier=project_id, login=login, display_printouts=True)

    def getUniqueUsers(self):
        """
        Provides a list of the usernames of all unique users who participated in classifications.

        Returns
        -------
        unique_users : list, strings
        """
        
        # Return the list of unique users
        return self.extracted_dataframe["user_name"].unique()

    def getClassificationsCount(self):
        """
        Provides the total number of classifications in the extracted classifications file.

        Returns
        -------
        count : int
            The total number of classifications in the extracted classifications file.
        """
        
        # Return the number of classifications
        return len(self.extracted_dataframe)

    def getUserClassifications(self, user_id):
        """
        Provides a dataframe of all classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        user_classifications : pandas.DataFrame
            The extracted dataframe of all classifications made by that user.
        """
        # Check if the user_id is a string or an integer
        if(isinstance(user_id, str)):
            # If it's a string, then it's a username
            user_name = user_id
            
            return self.extracted_dataframe[self.extracted_dataframe["user_name"] == user_name]
        else:
            # If it's an integer, then it's a Zooniverse ID
            return self.extracted_dataframe[self.extracted_dataframe["user_id"] == user_id]

    def getUserClassificationsCount(self, user_id):
        """
        Provides the total number of classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        count : int
            The total number of classifications made by that user.
        """
        
        # Return the number of classifications made by that user
        return len(self.getUserClassifications(user_id))

    def getSubjectIDs(self):
        """
        Provides a list of all subject IDs in the reduced classifications file.

        Returns
        -------
        subject_ids : list, strings
            A list of all subject IDs in the reduced classifications file.

        Notes
        -----
        This method is useful for iterating over all unique subjects.
        This will not include duplicates, such as would be found in the extracted classifications file.
        """
        
        # Return the list of subject IDs
        return self.reduced_dataframe["subject_id"].values

    def getSubjectDataframe(self, subject_id, reduced=True):
        """
        Provides the reduced dataframe of the classifications made for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.
        reduced : bool
            Whether or not to return the reduced dataframe (or the extracted dataframe). Default is True.

        Returns
        -------
        subject_dataframe : pandas.DataFrame
            The reduced (or extracted) dataframe of the classifications made for that subject.

        """
        
        # Check if the the subject row should be taken from the reduced or the extracted dataframe
        if(reduced):
            # If reduced, then return the reduced dataframe for that subject
            return self.reduced_dataframe[self.reduced_dataframe["subject_id"] == int(subject_id)]
        else:
            # If not reduced, then return the extracted dataframe for that subject
            return self.extracted_dataframe[self.extracted_dataframe["subject_id"] == int(subject_id)]

    def subjectClassifications(self, subject_id):
        """
        Provides a dictionary of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Returns
        -------
        classification_dict : dict
            A dictionary of the number of "yes" and "no" classifications for that subject.
        """

        # Get the subject's dataframe
        subject_dataframe = self.getSubjectDataframe(subject_id)

        try:
            # Try to get the number of "yes" classifications
            yes_count = int(subject_dataframe["data.yes"].values[0])
        except ValueError:
            # If there are no "yes" classifications, then set the count to 0
            yes_count = 0

        try:
            # Try to get the number of "no" classifications
            no_count = int(subject_dataframe["data.no"].values[0])
        except ValueError:
            # If there are no "no" classifications, then set the count to 0
            no_count = 0

        # Return the dictionary of the number of "yes" and "no" classifications
        return {"yes": yes_count, "no": no_count}

    def plotSubjectClassifications(self, subject_id):
        """
        Plots a pie chart of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Notes
        -----
        This method is useful for visualizing the number of "yes" and "no" classifications for a particular subject.
        In particular, this helps easily see whether or not a subject has been classified as a "yes" or "no" more often.
        """

        # Get the number of "yes" and "no" classifications for that subject as a dictionary
        classification_dict = self.subjectClassifications(subject_id)

        # Get the number of "yes" and "no" classifications from the dictionary
        yes_count = classification_dict["yes"]
        no_count = classification_dict["no"]

        # Compute the total number of classifications
        total_count = yes_count + no_count

        # Compute the percentage of "yes" and "no" classifications
        yes_percent = yes_count / total_count
        no_percent = no_count / total_count

        # Plot the pie chart
        plt.pie([yes_percent, no_percent], labels=["Yes", "No"], autopct='%1.1f%%')
        plt.axis('equal')
        plt.title("Subject ID: " + str(subject_id) + " Classifications")
        plt.legend([f"{yes_count} classifications", f"{no_count} classifications"])
        plt.show()

    def computeAverageTimePerClassification(self):
        """
        Computes the average time between classifications for all users.

        Returns
        -------
        users_average_time : float
            The average time between classifications for all users.

        Notes
        -----
        This method is useful for determining how long it typically takes users to make classifications.
        There is an upper time limit of 5 minutes between classifications when computing the average time.
        """

        # Get the unique user names
        user_names = self.getUniqueUsers()

        # Initialize the list of classification times
        users_classification_times = []

        # Iterate over all unique usernames
        for user_name in user_names:

            # Get the user's classifications
            user_classifications = self.getUserClassifications(user_name)

            # Convert the created_at column to datetime objects
            user_times = pd.to_datetime(user_classifications["created_at"])

            # Initialize the previous index
            previous_index = None

            # Iterate over all indices in the user's classifications
            for index in user_times.index:
                # If there is a previous index, then compute the time difference
                if(previous_index is not None):
                    # Compute the time difference between the current and previous classification
                    time_difference = user_times[index] - user_times[previous_index]

                    # Set the upper time limit to 5 minutes
                    upper_time_limit = 60*5

                    # If the time difference is less than the upper time limit, then add it to the list of classification times
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds
                                                          )
                # Set the previous index to the current index
                previous_index = index

        # Compute the average time between classifications for all users
        users_average_time = sum(users_classification_times) / len(users_classification_times)

        # Return the average time between classifications for all users
        return users_average_time

    def classificationTimeHistogram(self):
        """
        Plots a histogram of the time between classifications for all users.

        Notes
        -----
        This method is useful for visualizing the time between classifications for all users.
        There is an upper time limit of 5 minutes between classifications when computing the histogram.
        """

        # Get the unique usernames
        user_names = self.getUniqueUsers()

        # Initialize the list of classification times
        users_classification_times = []

        # Iterate over all unique usernames
        for user_name in user_names:
            # Get the user's classifications
            user_classifications = self.getUserClassifications(user_name)

            # Convert the created_at column to datetime objects
            user_times = pd.to_datetime(user_classifications["created_at"])

            # Initialize the previous index
            previous_index = None

            # Iterate over all indices in the user's classifications
            for index in user_times.index:
                # If there is a previous index, then compute the time difference
                if(previous_index is not None):
                    # Compute the time difference between the current and previous classification
                    time_difference = user_times[index] - user_times[previous_index]

                    # Set the upper time limit to 5 minutes
                    upper_time_limit = 60*5

                    # If the time difference is less than the upper time limit, then add it to the list of classification times
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds)

                # Set the previous index to the current index
                previous_index = index

        # Plot the histogram
        plt.hist(users_classification_times)
        plt.title("Classification Time Histogram")
        plt.xlabel("Time (seconds)")
        plt.ylabel("Count")
        plt.show()

    def classificationTimeline(self, bar=True, binning_parameter = "Day", **kwargs):
        """
        Plots a timeline of the classifications made for all subjects.

        Parameters
        ----------
        bar : bool
            Whether or not to plot the timeline as a bar graph. Default is True.
        binning_parameter : str
            The binning parameter for the timeline. Determines how the classifications
            should be binned. Default is "Day".
        **kwargs
            Keyword arguments to be passed to the plotting function.

        Notes
        -----
        This method is useful for visualizing the classifications made for all subjects over some period of time.
        """

        # Get the classification datetimes
        classification_datetimes = pd.to_datetime(self.extracted_dataframe["created_at"])

        # Initialize the binned datetimes dictionary
        binned_datetimes = {}

        # Iterate over all classification datetimes
        for classification_datetime in classification_datetimes:

            # Bin the datetimes
            if(binning_parameter == "Day"):
                day = classification_datetime.date()
                if day in binned_datetimes:
                    binned_datetimes[day].append(classification_datetime)
                else:
                    binned_datetimes[day] = [classification_datetime]
            elif(binning_parameter == "Week"):
                week = classification_datetime.isocalendar()[1]
                if week in binned_datetimes:
                    binned_datetimes[week].append(classification_datetime)
                else:
                    binned_datetimes[week] = [classification_datetime]
            elif(binning_parameter == "Month"):
                month = classification_datetime.month
                if month in binned_datetimes:
                    binned_datetimes[month].append(classification_datetime)
                else:
                    binned_datetimes[month] = [classification_datetime]
            elif(binning_parameter == "Year"):
                year = classification_datetime.year
                if year in binned_datetimes:
                    binned_datetimes[year].append(classification_datetime)
                else:
                    binned_datetimes[year] = [classification_datetime]

        # Convert the binned datetimes to a dictionary of counts
        binned_datetimes = {k: len(v) for k, v in binned_datetimes.items()}

        # Plot the timeline
        if(bar):
            plt.bar(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        else:
            plt.plot(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        plt.title("Classification Timeline")
        plt.xlabel(binning_parameter)
        plt.ylabel("Count")
        plt.show()

    def getSubject(self, subject_id):
        """
        Gets the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """

        # Get the subject with the given subject ID in the subject set with the given subject set ID
        return Spout.get_subject(int(subject_id), self.subject_set_id)

    def getSubjectMetadata(self, subject_id):
        """
        Gets the metadata for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata from.
        
        Returns
        -------
        metadata : dict
            The metadata for the subject with the given subject ID.
        """

        # Get the subject with the given subject ID
        subject = self.getSubject(subject_id)

        try:
            # Get the subject's metadata
            subject_metadata = subject.metadata

            # Return the subject's metadata
            return subject_metadata
        except AttributeError:
            # If the subject could not be found, then return None
            return None

    def getSubjectMetadataField(self, subject_id, field_name):
        """
        Gets the metadata field with the given field name for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata field from.
        field_name : str
            The name of the metadata field to get.
        
        Returns
        -------
        field_value : str
            The value of the metadata field with the given field name for the subject with the given subject ID.
        """

        # Get the subject's metadata
        subject_metadata = self.getSubjectMetadata(subject_id)
        try:
            # Get the metadata field with the given field name
            field_value = subject_metadata.get(field_name)

            # Return the metadata field value
            return field_value
        except AttributeError:
            # If the subject could not be found, then return None
            return None

    def showSubject(self, subject_id, open_in_browser=False):
        """
        Shows the subject with the given subject ID by opening the WiseView link in the default web browser
        and by returning the WiseView link.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to show.
        open_in_browser : bool
            Whether or not to open the subject in the default web browser. Default is False.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """

        # Get the WiseView link for the subject with the given subject ID
        wise_view_link = self.getSubjectMetadataField(subject_id, "WISEVIEW")

        # Return None if no WiseView link was found
        if(wise_view_link is None):
            return None

        # Remove the WiseView link prefix and suffix
        wise_view_link = wise_view_link.removeprefix("[WiseView](+tab+")
        wise_view_link = wise_view_link.removesuffix(")")

        # Determine whether or not to open the subject in the default web browser
        if wise_view_link is None:
            print(f"No WiseView link found for subject {subject_id}")
            return None
        else:
            if(open_in_browser):
                webbrowser.open(wise_view_link)

        # Return the WiseView link
        return wise_view_link

    def getSIMBADLink(self, subject_id):
        """
        Gets the SIMBAD link for the subject with the given subject ID.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the SIMBAD link for.

        Returns
        -------
        simbad_link : str
            The SIMBAD link for the subject with the given subject ID.
        """

        simbad_link = self.getSubjectMetadataField(subject_id, "SIMBAD")

        if (simbad_link is None):
            return None

            # Remove the SIMBAD link prefix and suffix
        simbad_link = simbad_link.removeprefix("[SIMBAD](+tab+")
        simbad_link = simbad_link.removesuffix(")")

        return simbad_link

    def getSIMBADQuery(self, subject_id, *args):
        # Get the subject's metadata
        simbad_link = self.getSIMBADLink(subject_id)

        if(simbad_link is None):
            return None

        def extract_coordinates_from_link(link):
            # Extract the coordinate section from the link
            coord_start = link.find("Coord=") + len("Coord=")
            coord_end = link.find("&", coord_start)
            coordinate_section = link[coord_start:coord_end]

            # Split the coordinate section into RA and DEC
            ra, dec = coordinate_section.split("+")

            return float(ra), float(dec)

        def extract_radius_from_link(link):
            # Find the index of "Radius=" in the link
            radius_start = link.find("Radius=") + len("Radius=")

            # Find the index of "&" after the radius value
            radius_end = link.find("&", radius_start)

            # Extract the radius value
            radius = link[radius_start:radius_end]

            return float(radius)

        # Get RA and Dec from the SIMBAD link
        RA, DEC = extract_coordinates_from_link(simbad_link)

        # Get the radius from the SIMBAD link
        radius = extract_radius_from_link(simbad_link)

        result = SIMBADChecker.getSIMBADQuery(RA, DEC, radius, *args)
        return result

    def checkSIMBADQuery(self, subject_id, otypes=["BD*", "BD?", "BrownD*", "BrownD?", "BrownD*_Candidate", "PM*"], *args):
        # Get the subject's metadata
        simbad_link = self.getSIMBADLink(subject_id)

        if(simbad_link is None):
            return None

        def extract_coordinates_from_link(link):
            # Extract the coordinate section from the link
            coord_start = link.find("Coord=") + len("Coord=")
            coord_end = link.find("&", coord_start)
            coordinate_section = link[coord_start:coord_end]

            # Split the coordinate section into RA and DEC
            ra, dec = coordinate_section.split("+")

            return float(ra), float(dec)

        def extract_radius_from_link(link):
            # Find the index of "Radius=" in the link
            radius_start = link.find("Radius=") + len("Radius=")

            # Find the index of "&" after the radius value
            radius_end = link.find("&", radius_start)

            # Extract the radius value
            radius = link[radius_start:radius_end]

            return float(radius)

        # Get RA and Dec from the SIMBAD link
        RA, DEC = extract_coordinates_from_link(simbad_link)

        # Get the radius from the SIMBAD link
        radius = extract_radius_from_link(simbad_link)


        conditional_arg = SIMBADChecker.buildConditionalArgument("otypes", "==", otypes)
        simbad_checker = SIMBADChecker(conditional_arg)
        simbad_checker.getQuery(RA, DEC, radius, *args)
        result = simbad_checker.checkQuery()
        return result

    def isInSIMBAD(self, subject_id):
        """
        Determines whether or not the subject is in SIMBAD.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        in_simbad : bool
            Whether or not the subject is in SIMBAD.
        """

        # Get the subject's metadata
        simbad_link = self.getSIMBADLink(subject_id)

        if(simbad_link is None):
            return False

        def extract_coordinates_from_link(link):
            # Extract the coordinate section from the link
            coord_start = link.find("Coord=") + len("Coord=")
            coord_end = link.find("&", coord_start)
            coordinate_section = link[coord_start:coord_end]

            # Split the coordinate section into RA and DEC
            ra, dec = coordinate_section.split("+")

            return float(ra), float(dec)

        def extract_radius_from_link(link):
            # Find the index of "Radius=" in the link
            radius_start = link.find("Radius=") + len("Radius=")

            # Find the index of "&" after the radius value
            radius_end = link.find("&", radius_start)

            # Extract the radius value
            radius = link[radius_start:radius_end]

            return float(radius)

        # Get RA and Dec from the SIMBAD link
        RA, DEC = extract_coordinates_from_link(simbad_link)

        # Get the radius from the SIMBAD link
        radius = extract_radius_from_link(simbad_link)

        return SIMBADChecker.isInSIMBAD(RA, DEC, radius)

    def subjectExists(self, subject_id):
        """
        Determines whether or not the subject exists.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        subject_exists : bool
            Whether or not the subject exists.
        """

        # Get the subject's metadata
        metadata = self.getSubjectMetadata(subject_id)

        # Return whether or not the subject exists
        return metadata is not None

    @staticmethod
    def bitmaskToType(bitmask):
        """
        Converts a bitmask to a subject type.
        
        Parameters
        ----------
        bitmask : int, str
            The bitmask value to convert to a subject type.
        
        Returns
        -------
        bitmask_type : str
            The subject type associated with the bitmask value.
        """

        # Convert the bitmask to an integer
        try:
            bitmask = int(bitmask)
        except ValueError:
            raise ValueError("bitmask must be an integer or a string that can be converted to an integer.")

        # Initialize the bitmask dictionary
        bitmask_dict = {2**0: "SMDET Candidate", 2**1: "Blank", 2**2: "Known Brown Dwarf", 2**3: "Quasar", 2**4: "Random Sky Location", 2**5: "White Dwarf"}

        # Return the bitmask type associated with the bitmask value
        return bitmask_dict.get(bitmask, None)

    def determineSuccessCount(self):
        """
        Determines the success count of each subject type.
        
        Returns
        -------
        success_count_dict : dict
            A dictionary containing the success count of each subject type,
            if there is a known correct answer.

        Notes
        -----
        The success count is the number of subjects of a given type that have been classified correctly.
        This is only applicable to subjects that have a known correct answer, such as known brown dwarfs, quasars,
        white dwarfs, and random sky locations.
        """

        # Get the subject IDs
        subject_ids = self.getSubjectIDs()

        # Initialize the success count dictionary
        success_count_dict = {}

        # Iterate through the subject IDs
        for subject_id in subject_ids:

            # Get the bitmask for the subject
            try:
                bitmask = self.getSubjectMetadataField(subject_id, "#BITMASK")
            except AttributeError:
                continue

            # Convert the bitmask to a subject type
            bitmask_type = self.bitmaskToType(bitmask)

            # If the bitmask type is None, continue
            if bitmask_type is None:
                continue

            # If the bitmask type is not in the success count dictionary, add it
            if bitmask_type not in success_count_dict:
                success_count_dict[bitmask_type] = {"total": 0, "success": 0}

            # Increment the total count for the bitmask type
            success_count_dict[bitmask_type]["total"] += 1

            # Get the subject classifications
            subject_classifications = self.subjectClassifications(subject_id)

            # Count the number of successful classifications for each of the bitmask types
            if(bitmask_type == "Known Brown Dwarf"):
                if(subject_classifications["yes"] > subject_classifications["no"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "Quasar"):
                if(subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "White Dwarf"):
                if(subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "SMDET Candidate"):
                success_count_dict[bitmask_type]["success"] = None
            elif(bitmask_type == "Random Sky Location"):
                if (subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1

        # Return the success count dictionary
        return success_count_dict

