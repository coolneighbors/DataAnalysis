import datetime
import os
import pickle

import pandas as pd
import webbrowser
import matplotlib.pyplot as plt

from unWISE_verse.Spout import Spout


class Analyzer:
    def __init__(self, extracted_file, reduced_file, save_login=True):
        """
        Initializes an Analyzer object, which is used to analyze the extracted and reduced classifications from a
        Zooniverse project.

        Parameters
        ----------
            extracted_file : str
                The path to the extracted classifications file, generated by the Classifier class.
            reduced_file : str
                The path to the reduced classifications file, generated by the Classifier class.
            save_login : bool
                Whether or not to save the login information to a file, including Zooniverse IDs. Default is True.
        Notes
        -----
        This class is used to analyze the extracted and reduced classifications from a Zooniverse project.
        The extracted classifications file is a CSV file containing all of the classifications made by all users.
        The reduced classifications file is a CSV file containing the reduced classifications for each subject.
        """

        self.extracted_file = extracted_file
        self.reduced_file = reduced_file
        self.extracted_dataframe = pd.read_csv(self.extracted_file)
        self.reduced_dataframe = pd.read_csv(self.reduced_file)
        self.subject_set_id = None
        self.login(save_login)

    def login(self, save=True):
        """
        Logs into Zooniverse using Spout and saves the login information and Zooniverse IDs each to a file.

        Parameters
        ----------
        save : bool
            Whether or not to save the login information to a file, including Zooniverse IDs. Default is True.

        Notes
        -----
        This method is called by the __init__ method automatically. If you want to login to a different
        Zooniverse account, delete the login.pickle file. If you want to login to the same account,
        but with different Zooniverse IDs, delete the zooniverse_ids.pickle file.
        """

        # Login
        login = Spout.requestLogin(save=save)

        # IDs
        project_id, self.subject_set_id = Spout.requestZooniverseIDs(save=save)

        # Create Spout object to access Zooniverse project
        Spout(project_identifier=project_id, login=login, display_printouts=True)

    def getUniqueUsers(self):
        """
        Provides a list of the usernames of all unique users who participated in classifications.

        Returns
        -------
        unique_users : list, strings
        """

        return self.extracted_dataframe["user_name"].unique()

    def getClassificationsCount(self):
        """
        Provides the total number of classifications in the extracted classifications file.

        Returns
        -------
        count : int
            The total number of classifications in the extracted classifications file.
        """

        return len(self.extracted_dataframe)

    def getUserClassifications(self, user_id):
        """
        Provides a dataframe of all classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        user_classifications : pandas.DataFrame
            The extracted dataframe of all classifications made by that user.
        """

        if(isinstance(user_id, str)):
            user_name = user_id
            return self.extracted_dataframe[self.extracted_dataframe["user_name"] == user_name]
        else:
            return self.extracted_dataframe[self.extracted_dataframe["user_id"] == user_id]

    def getUserClassificationsCount(self, user_id):
        """
        Provides the total number of classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        count : int
            The total number of classifications made by that user.
        """

        return len(self.getUserClassifications(user_id))

    def getSubjectIDs(self):
        """
        Provides a list of all subject IDs in the reduced classifications file.

        Returns
        -------
        subject_ids : list, strings
            A list of all subject IDs in the reduced classifications file.

        Notes
        -----
        This method is useful for iterating over all unique subjects.
        This will not include duplicates, such as would be found in the extracted classifications file.
        """

        return self.reduced_dataframe["subject_id"].values

    def getSubjectRow(self, subject_id, reduced=True):
        """
        Provides the reduced dataframe of the classifications made for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.
        reduced : bool
            Whether or not to return the reduced dataframe (or the extracted dataframe). Default is True.

        Returns
        -------
        subject_row : pandas.DataFrame
            The reduced (or extracted) dataframe of the classifications made for that subject.

        """

        if(reduced):
            return self.reduced_dataframe[self.reduced_dataframe["subject_id"] == int(subject_id)]
        else:
            return self.extracted_dataframe[self.extracted_dataframe["subject_id"] == int(subject_id)]

    def subjectClassifications(self, subject_id):
        """
        Provides a dictionary of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Returns
        -------
        classification_dict : dict
            A dictionary of the number of "yes" and "no" classifications for that subject.
        """

        subject_row = self.getSubjectRow(subject_id)
        try:
            yes_count = int(subject_row["data.yes"].values[0])
        except ValueError:
            yes_count = 0

        try:
            no_count = int(subject_row["data.no"].values[0])
        except ValueError:
            no_count = 0

        return {"yes": yes_count, "no": no_count}

    def plotSubjectClassifications(self, subject_id):
        """
        Plots a pie chart of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Notes
        -----
        This method is useful for visualizing the number of "yes" and "no" classifications for a particular subject.
        In particular, this helps easily see whether or not a subject has been classified as a "yes" or "no" more often.
        """

        classification_dict = self.subjectClassifications(subject_id)
        yes_count = classification_dict["yes"]
        no_count = classification_dict["no"]
        total_count = yes_count + no_count
        yes_percent = yes_count / total_count
        no_percent = no_count / total_count

        plt.pie([yes_percent, no_percent], labels=["Yes", "No"], autopct='%1.1f%%')
        plt.axis('equal')
        plt.title("Subject ID: " + str(subject_id) + " Classifications")
        plt.legend([f"{yes_count} classifications", f"{no_count} classifications"])
        plt.show()

    def computeAverageTimePerClassification(self):
        """
        Computes the average time between classifications for all users.

        Returns
        -------
        users_average_time : float
            The average time between classifications for all users.

        Notes
        -----
        This method is useful for determining how long it typically takes users to make classifications.
        There is an upper time limit of 5 minutes between classifications when computing the average time.
        """

        user_names = self.getUniqueUsers()
        users_classification_times = []
        for user_name in user_names:
            user_classifications = self.getUserClassifications(user_name)
            user_times = pd.to_datetime(user_classifications["created_at"])
            previous_index = None
            for index in user_times.index:
                if(previous_index is not None):
                    time_difference = user_times[index] - user_times[previous_index]
                    upper_time_limit = 60*5
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds)
                previous_index = index
        users_average_time = sum(users_classification_times) / len(users_classification_times)
        return users_average_time

    def classificationTimeHistogram(self):
        """
        Plots a histogram of the time between classifications for all users.

        Notes
        -----
        This method is useful for visualizing the time between classifications for all users.
        There is an upper time limit of 5 minutes between classifications when computing the histogram.
        """

        user_names = self.getUniqueUsers()
        users_classification_times = []
        for user_name in user_names:
            user_classifications = self.getUserClassifications(user_name)
            user_times = pd.to_datetime(user_classifications["created_at"])
            previous_index = None
            for index in user_times.index:
                if(previous_index is not None):
                    time_difference = user_times[index] - user_times[previous_index]
                    upper_time_limit = 60*5
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds)
                previous_index = index
        plt.hist(users_classification_times)
        plt.title("Classification Time Histogram")
        plt.xlabel("Time (seconds)")
        plt.ylabel("Count")
        plt.show()

    def classificationTimeline(self, bar=True, binning_parameter = "Day", **kwargs):
        """
        Plots a timeline of the classifications made for all subjects.

        Parameters
        ----------
        bar : bool
            Whether or not to plot the timeline as a bar graph. Default is True.
        binning_parameter : str
            The binning parameter for the timeline. Determines how the classifications
            should be binned. Default is "Day".
        **kwargs
            Keyword arguments to be passed to the plotting function.

        Notes
        -----
        This method is useful for visualizing the classifications made for all subjects over some period of time.
        """

        classification_datetimes = pd.to_datetime(self.extracted_dataframe["created_at"])
        binned_datetimes = {}
        for classification_datetime in classification_datetimes:
            if(binning_parameter == "Day"):
                day = classification_datetime.date()
                if day in binned_datetimes:
                    binned_datetimes[day].append(classification_datetime)
                else:
                    binned_datetimes[day] = [classification_datetime]
            elif(binning_parameter == "Week"):
                week = classification_datetime.isocalendar()[1]
                if week in binned_datetimes:
                    binned_datetimes[week].append(classification_datetime)
                else:
                    binned_datetimes[week] = [classification_datetime]
            elif(binning_parameter == "Month"):
                month = classification_datetime.month
                if month in binned_datetimes:
                    binned_datetimes[month].append(classification_datetime)
                else:
                    binned_datetimes[month] = [classification_datetime]
            elif(binning_parameter == "Year"):
                year = classification_datetime.year
                if year in binned_datetimes:
                    binned_datetimes[year].append(classification_datetime)
                else:
                    binned_datetimes[year] = [classification_datetime]
        binned_datetimes = {k: len(v) for k, v in binned_datetimes.items()}
        if(bar):
            plt.bar(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        else:
            plt.plot(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        plt.title("Classification Timeline")
        plt.xlabel(binning_parameter)
        plt.ylabel("Count")
        plt.show()

    def getSubject(self, subject_id):
        """
        Gets the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """
        
        return Spout.get_subject(int(subject_id), self.subject_set_id)

    def getSubjectMetadata(self, subject_id):
        """
        Gets the metadata for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata from.
        
        Returns
        -------
        metadata : dict
            The metadata for the subject with the given subject ID.
        """
        
        subject = self.getSubject(subject_id)
        return subject.metadata

    def getSubjectMetadataField(self, subject_id, field_name):
        """
        Gets the metadata field with the given field name for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata field from.
        field_name : str
            The name of the metadata field to get.
        
        Returns
        -------
        field_value : str
            The value of the metadata field with the given field name for the subject with the given subject ID.
        """
        
        subject_metadata = self.getSubjectMetadata(subject_id)
        return subject_metadata.get(field_name)

    def showSubject(self, subject_id, open_in_browser=False):
        """
        Shows the subject with the given subject ID by opening the WiseView link in the default web browser
        and by returning the WiseView link.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to show.
        open_in_browser : bool
            Whether or not to open the subject in the default web browser. Default is False.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """
        
        wise_view_link = self.getSubjectMetadataField(subject_id, "WISEVIEW")
        wise_view_link = wise_view_link.removeprefix("[WiseView](+tab+")
        wise_view_link = wise_view_link.removesuffix(")")
        if wise_view_link is None:
            print(f"No WiseView link found for subject {subject_id}")
            return None
        else:
            if(open_in_browser):
                webbrowser.open(wise_view_link)
        return wise_view_link

    @staticmethod
    def bitmaskToType(bitmask):
        """
        Converts a bitmask to a subject type.
        
        Parameters
        ----------
        bitmask : int, str
            The bitmask value to convert to a subject type.
        
        Returns
        -------
        bitmask_type : str
            The subject type associated with the bitmask value.
        """
        
        try:
            bitmask = int(bitmask)
        except ValueError:
            raise ValueError("bitmask must be an integer or a string that can be converted to an integer.")

        bitmask_dict = {2**0: "SMDET Candidate", 2**1: "Blank", 2**2: "Known Brown Dwarf", 2**3: "Quasar", 2**4: "Random Sky Location", 2**5: "White Dwarf"}
        return bitmask_dict.get(bitmask, None)

    def determineSuccessCount(self):
        """
        Determines the success count of each subject type.
        
        Returns
        -------
        success_count_dict : dict
            A dictionary containing the success count of each subject type,
            if there is a known correct answer.

        Notes
        -----
        The success count is the number of subjects of a given type that have been classified correctly.
        This is only applicable to subjects that have a known correct answer, such as known brown dwarfs, quasars,
        white dwarfs, and random sky locations.
        """
        
        subject_ids = self.getSubjectIDs()
        success_count_dict = {}
        for subject_id in subject_ids:
            try:
                bitmask = self.getSubjectMetadataField(subject_id, "#BITMASK")
            except AttributeError:
                continue
            bitmask_type = self.bitmaskToType(bitmask)
            if bitmask_type is None:
                continue
            if bitmask_type not in success_count_dict:
                success_count_dict[bitmask_type] = {"total": 0, "success": 0}
            success_count_dict[bitmask_type]["total"] += 1
            subject_classifications = self.subjectClassifications(subject_id)

            if(bitmask_type == "Known Brown Dwarf"):
                if(subject_classifications["yes"] > subject_classifications["no"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "Quasar"):
                if(subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "White Dwarf"):
                if(subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1
            elif(bitmask_type == "SMDET Candidate"):
                success_count_dict[bitmask_type]["success"] = None
            elif(bitmask_type == "Random Sky Location"):
                if (subject_classifications["no"] > subject_classifications["yes"]):
                    success_count_dict[bitmask_type]["success"] += 1

        return success_count_dict