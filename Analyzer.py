import datetime
import math
import os
import pickle
import warnings
from copy import copy

import astropy
import numpy as np
import pandas
import pandas as pd
import webbrowser
import matplotlib.pyplot as plt
from astropy.coordinates import SkyCoord
import astropy.units as u
from astropy.time import Time
from astroquery.simbad import Simbad
import functools
from unWISE_verse.Spout import Spout
from Searcher import SimbadSearcher, GaiaSearcher
from Plotter import SubjectCSVPlotter


class Analyzer:
    def __init__(self, extracted_file, reduced_file, subjects_file=None, save_login=True):
        """
        Initializes an Analyzer object, which is used to analyze the extracted and reduced classifications from a
        Zooniverse project.

        Parameters
        ----------
            extracted_file : str
                The path to the extracted classifications file, generated by the Classifier class.
            reduced_file : str
                The path to the reduced classifications file, generated by the Classifier class.
            save_login : bool
                Whether to save the login information to a file, including Zooniverse IDs. Default is True.
        Notes
        -----
        This class is used to analyze the extracted and reduced classifications from a Zooniverse project.
        The extracted classifications file is a CSV file containing all of the classifications made by all users.
        The reduced classifications file is a CSV file containing the reduced classifications for each subject.
        """
        
        # Initialize variables
        self.extracted_file = extracted_file
        self.reduced_file = reduced_file
        self.extracted_dataframe = pd.read_csv(self.extracted_file)
        self.reduced_dataframe = pd.read_csv(self.reduced_file)

        if (subjects_file is not None):
            self.subjects_file = subjects_file
            self.subjects_dataframe = pd.read_csv(self.subjects_file)
        else:
            self.subjects_file = None
            self.subjects_dataframe = None
            self.subject_set_id = None
            self.login(save_login)

    def login(self, save=True):
        """
        Logs into Zooniverse using Spout and saves the login information and Zooniverse IDs each to a file.

        Parameters
        ----------
        save : bool
            Whether to save the login information to a file, including Zooniverse IDs. Default is True.

        Notes
        -----
        This method is called by the __init__ method automatically. If you want to login to a different
        Zooniverse account, delete the login.pickle file. If you want to login to the same account,
        but with different Zooniverse IDs, delete the zooniverse_ids.pickle file.
        """

        # Get login
        login = Spout.requestLogin(save=save)

        # Get Zooniverse IDs
        project_id, self.subject_set_id = Spout.requestZooniverseIDs(save=save)

        # Create Spout object to access the Zooniverse project
        Spout(project_identifier=project_id, login=login, display_printouts=True)

    def getUniqueUsers(self, include_logged_out=True):
        """
        Provides a list of the usernames of all unique users who participated in classifications.

        Returns
        -------
        unique_users : list, strings
        """

        if(include_logged_out):
            return self.extracted_dataframe["user_name"].unique()
        else:
            unique_users = self.extracted_dataframe["user_name"].unique()
            logged_in_unique_users = [user for user in unique_users if "not-logged-in" not in user]
            return logged_in_unique_users

    def getClassificationsCount(self):
        """
        Provides the total number of classifications in the extracted classifications file.

        Returns
        -------
        count : int
            The total number of classifications in the extracted classifications file.
        """
        
        # Return the number of classifications
        return len(self.extracted_dataframe)

    def getUserClassifications(self, user_id):
        """
        Provides a dataframe of all classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        user_classifications : pandas.DataFrame
            The extracted dataframe of all classifications made by that user.
        """
        # Check if the user_id is a string or an integer
        if(isinstance(user_id, str)):
            # If it's a string, then it's a username
            user_name = user_id
            
            return self.extracted_dataframe[self.extracted_dataframe["user_name"] == user_name]
        else:
            # If it's an integer, then it's a Zooniverse ID
            return self.extracted_dataframe[self.extracted_dataframe["user_id"] == user_id]

    def getUserClassificationsCount(self, user_id):
        """
        Provides the total number of classifications made by a particular user.

        Parameters
        ----------
        user_id : int, str
            The user's Zooniverse ID or username.

        Returns
        -------
        count : int
            The total number of classifications made by that user.
        """
        
        # Return the number of classifications made by that user
        return len(self.getUserClassifications(user_id))

    def getTopUsers(self, count_threshold=None, percentile=None):

        if (count_threshold is None and percentile is None):
            raise ValueError("You must provide either a count_threshold or a percentile.")
        elif(count_threshold is not None and percentile is not None):
            raise ValueError("You cannot provide both a count_threshold and a percentile.")

        unique_users = self.getUniqueUsers()
        user_classifications_dict = {}

        for unique_user in unique_users:
            user_classifications_dict[unique_user] = self.getUserClassificationsCount(unique_user)

        # Sort the dictionary by the number of classifications
        sorted_user_classifications_dict = {k: v for k, v in sorted(user_classifications_dict.items(), key=lambda item: item[1])}

        # Reverse the dictionary
        sorted_user_classifications_dict = dict(reversed(list(sorted_user_classifications_dict.items())))

        top_users_dict = {}

        def userMeetsRequirements(user, count_threshold, percentile):
            if(percentile is not None):
                if(sorted_user_classifications_dict[user] >= np.percentile(list(sorted_user_classifications_dict.values()), percentile)):
                    return True
                else:
                    return False
            else:
                if(sorted_user_classifications_dict[user] >= count_threshold):
                    return True
                else:
                    return False

        for user in sorted_user_classifications_dict:
            if(userMeetsRequirements(user, count_threshold, percentile)):
                top_users_dict[user] = sorted_user_classifications_dict[user]
        return top_users_dict

    def getTopUsersCount(self, count_threshold=None, percentile=None):
        top_users_dict = self.getTopUsers(count_threshold=count_threshold, percentile=percentile)
        return len(top_users_dict)

    def getTopUsersClassificationsCount(self, count_threshold=None, percentile=None):
        top_users_dict = self.getTopUsers(count_threshold=count_threshold, percentile=percentile)
        return sum(top_users_dict.values())

    def plotTopUsersClassificationCounts(self, count_threshold=None, percentile=None, **kwargs):
        top_users_dict = self.getTopUsers(count_threshold=count_threshold, percentile=percentile)
        # Plot the number of classifications made by each user but stop names from overlapping
        usernames = list(top_users_dict.keys())
        user_counts = list(top_users_dict.values())
        # Generate x-coordinates for the bars
        x = np.arange(len(top_users_dict))

        # Create the bar plot
        fig, ax = plt.subplots()

        if ("title" in kwargs):
            plt.title(kwargs["title"])
            del kwargs["title"]
        else:
            if (percentile is not None):
                plt.title(f"Users in the Top {100 - percentile}% of Classifications")
            elif (count_threshold is not None):
                plt.title(f"Users with More Than {count_threshold} Classifications")

        if ("ylabel" in kwargs):
            plt.ylabel(kwargs["ylabel"])
            del kwargs["ylabel"]
        else:
            plt.ylabel("Number of Classifications", fontsize=15)

        bars = ax.bar(x, user_counts, **kwargs)

        for i, bar in enumerate(bars):
            # Display the username below the bar, but angled 45 degrees
            offset = 0.2
            ax.text(bar.get_x() + bar.get_width() / 2 + offset, -5, usernames[i], ha='right', va='top', rotation=45)

            # Display the user's count
            ax.text(bar.get_x() + bar.get_width() / 2, user_counts[i] + 10, str(user_counts[i]), horizontalalignment='center', verticalalignment='bottom', fontsize=10)

        # Customize the plot
        ax.set_xticks(x)
        ax.set_xticklabels([])

        plt.show()

    def getSubjectIDs(self):
        """
        Provides a list of all subject IDs in the reduced classifications file.

        Returns
        -------
        subject_ids : list, strings
            A list of all subject IDs in the reduced classifications file.

        Notes
        -----
        This method is useful for iterating over all unique subjects.
        This will not include duplicates, such as would be found in the extracted classifications file.
        """
        
        # Return the list of subject IDs
        return self.reduced_dataframe["subject_id"].values

    def getSubjectDataframe(self, subject_id, type="default"):
        """
        Provides the reduced dataframe of the classifications made for a particular subject.

        Parameters
        ----------
        subject_id : str or int, or list of str or int, or tuple of str or int
            The subject's Zooniverse ID.
        type : str, optional
            The type of dataframe to return. Can be either "reduced", "extracted", or default.
            Default is taken from the subject's metadata.

        Returns
        -------
        subject_dataframe : pandas.DataFrame or list of pandas.DataFrame
            The dataframe(s) for that subject or subjects.
        """

        if(isinstance(subject_id, list) or isinstance(subject_id, tuple)):
            # If the subject_id is a list or tuple, then return a list of dataframes
            subject_dataframes = []
            for id in subject_id:
                subject_dataframes.append(self.getSubjectDataframe(id, type=type))
            return subject_dataframes

        if(type == "default"):
            # If default, then return the metadata of the subject as a dataframe
            subject_metadata = self.getSubjectMetadata(subject_id)

            # Add the standard subject_id column
            subject_metadata["subject_id"] = subject_id

            # Add the standard metadata column
            subject_metadata["metadata"] = str(subject_metadata)

            # Convert the metadata to a dataframe
            subject_metadata_dataframe = pd.DataFrame.from_dict(subject_metadata, orient="index").transpose()
            return subject_metadata_dataframe

        elif(type == "reduced"):
            # If reduced, then return the reduced dataframe for that subject
            return self.reduced_dataframe[self.reduced_dataframe["subject_id"] == int(subject_id)]
        elif(type == "extracted"):
            # If not reduced, then return the extracted dataframe for that subject
            return self.extracted_dataframe[self.extracted_dataframe["subject_id"] == int(subject_id)]

    def getSubjectClassifications(self, subject_id):
        """
        Provides a dictionary of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Returns
        -------
        classification_dict : dict
            A dictionary of the number of "yes" and "no" classifications for that subject.
        """

        # Get the subject's dataframe
        subject_dataframe = self.getSubjectDataframe(subject_id, type="reduced")

        try:
            # Try to get the number of "yes" classifications
            yes_count = int(subject_dataframe["data.yes"].values[0])
        except ValueError:
            # If there are no "yes" classifications, then set the count to 0
            yes_count = 0

        try:
            # Try to get the number of "no" classifications
            no_count = int(subject_dataframe["data.no"].values[0])
        except ValueError:
            # If there are no "no" classifications, then set the count to 0
            no_count = 0

        # Return the dictionary of the number of "yes" and "no" classifications
        return {"yes": yes_count, "no": no_count}

    def getClassificationCountDict(self, total_subject_count=None):
        subject_ids = self.getSubjectIDs()
        number_of_classifications_dict = {}
        for subject_id in subject_ids:
            classification_dict = self.getSubjectClassifications(subject_id)
            total_classifications = classification_dict['yes'] + classification_dict['no']
            if (total_classifications in number_of_classifications_dict):
                number_of_classifications_dict[total_classifications] += 1
            else:
                number_of_classifications_dict[total_classifications] = 1

        if(total_subject_count is not None):
            number_of_classifications_dict[0] = total_subject_count - len(subject_ids)
        number_of_classifications_dict = dict(sorted(number_of_classifications_dict.items()))
        return number_of_classifications_dict

    def getSubsetClassificationCount(self, minimum_count=0, total_subject_count=None):
        classification_count_dict = self.getClassificationCountDict(total_subject_count)
        return sum(value for key, value in classification_count_dict.items() if key >= minimum_count)

    def plotClassificationDistribution(self, total_subject_count=None, **kwargs):
        # if title is in kwargs, then remove it and put its value in the title
        if("title" in kwargs):
            plt.title(kwargs["title"])
            del kwargs["title"]
        else:
            plt.title("Classification Distribution")

        if("xlabel" in kwargs):
            plt.xlabel(kwargs["xlabel"])
            del kwargs["xlabel"]
        else:
            plt.xlabel("Number of Classifications")
        if("ylabel" in kwargs):
            plt.ylabel(kwargs["ylabel"])
            del kwargs["ylabel"]
        else:
            plt.ylabel("Number of Subjects")

        number_of_classifications_dict = self.getClassificationCountDict(total_subject_count)

        plt.bar(number_of_classifications_dict.keys(), number_of_classifications_dict.values(), **kwargs)

        for key in number_of_classifications_dict:
            plt.text(key, number_of_classifications_dict[key], number_of_classifications_dict[key], ha='center', va='bottom')

        plt.xticks(range(len(number_of_classifications_dict)))
        plt.show()

    def plotSubjectClassifications(self, subject_id):
        """
        Plots a pie chart of the number of "yes" and "no" classifications for a particular subject.

        Parameters
        ----------
        subject_id : str or int
            The subject's Zooniverse ID.

        Notes
        -----
        This method is useful for visualizing the number of "yes" and "no" classifications for a particular subject.
        In particular, this helps easily see whether a subject has been classified as a "yes" or "no" more often.
        """

        # Get the number of "yes" and "no" classifications for that subject as a dictionary
        classification_dict = self.getSubjectClassifications(subject_id)

        # Get the number of "yes" and "no" classifications from the dictionary
        yes_count = classification_dict["yes"]
        no_count = classification_dict["no"]

        # Compute the total number of classifications
        total_count = yes_count + no_count

        # Compute the percentage of "yes" and "no" classifications
        yes_percent = yes_count / total_count
        no_percent = no_count / total_count

        # Plot the pie chart
        plt.pie([yes_percent, no_percent], labels=["Yes", "No"], autopct='%1.1f%%')
        plt.axis('equal')
        plt.title("Subject ID: " + str(subject_id) + " Classifications")
        plt.legend([f"{yes_count} classifications", f"{no_count} classifications"])
        plt.show()

    def computeAverageTimePerClassification(self):
        """
        Computes the average time between classifications for all users.

        Returns
        -------
        users_average_time : float
            The average time between classifications for all users.

        Notes
        -----
        This method is useful for determining how long it typically takes users to make classifications.
        There is an upper time limit of 5 minutes between classifications when computing the average time.
        """

        # Get the unique usernames
        user_names = self.getUniqueUsers()

        # Initialize the list of classification times
        users_classification_times = []

        # Iterate over all unique usernames
        for user_name in user_names:

            # Get the user's classifications
            user_classifications = self.getUserClassifications(user_name)

            # Convert the created_at column to datetime objects
            user_times = pd.to_datetime(user_classifications["created_at"])

            # Initialize the previous index
            previous_index = None

            # Iterate over all indices in the user's classifications
            for index in user_times.index:
                # If there is a previous index, then compute the time difference
                if(previous_index is not None):
                    # Compute the time difference between the current and previous classification
                    time_difference = user_times[index] - user_times[previous_index]

                    # Set the upper time limit to 5 minutes
                    upper_time_limit = 60*5

                    # If the time difference is less than the upper time limit, then add it to the list of classification times
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds
                                                          )
                # Set the previous index to the current index
                previous_index = index

        # Compute the average time between classifications for all users
        users_average_time = sum(users_classification_times) / len(users_classification_times)

        # Return the average time between classifications for all users
        return users_average_time

    def classificationTimeHistogram(self):
        """
        Plots a histogram of the time between classifications for all users.

        Notes
        -----
        This method is useful for visualizing the time between classifications for all users.
        There is an upper time limit of 5 minutes between classifications when computing the histogram.
        """

        # Get the unique usernames
        user_names = self.getUniqueUsers()

        # Initialize the list of classification times
        users_classification_times = []

        # Iterate over all unique usernames
        for user_name in user_names:
            # Get the user's classifications
            user_classifications = self.getUserClassifications(user_name)

            # Convert the created_at column to datetime objects
            user_times = pd.to_datetime(user_classifications["created_at"])

            # Initialize the previous index
            previous_index = None

            # Iterate over all indices in the user's classifications
            for index in user_times.index:
                # If there is a previous index, then compute the time difference
                if(previous_index is not None):
                    # Compute the time difference between the current and previous classification
                    time_difference = user_times[index] - user_times[previous_index]

                    # Set the upper time limit to 5 minutes
                    upper_time_limit = 60*5

                    # If the time difference is less than the upper time limit, then add it to the list of classification times
                    if(time_difference.seconds < upper_time_limit):
                        users_classification_times.append(time_difference.seconds)

                # Set the previous index to the current index
                previous_index = index

        # Plot the histogram
        plt.hist(users_classification_times)
        plt.title("Classification Time Histogram")
        plt.xlabel("Time (seconds)")
        plt.ylabel("Count")
        plt.show()

    def classificationTimeline(self, bar=True, binning_parameter = "Day", **kwargs):
        """
        Plots a timeline of the classifications made for all subjects.

        Parameters
        ----------
        bar : bool
            Whether to plot the timeline as a bar graph. Default is True.
        binning_parameter : str
            The binning parameter for the timeline. Determines how the classifications
            should be binned. Default is "Day".
        **kwargs
            Keyword arguments to be passed to the plotting function.

        Notes
        -----
        This method is useful for visualizing the classifications made for all subjects over some period of time.
        """

        # Get the classification datetimes
        classification_datetimes = pd.to_datetime(self.extracted_dataframe["created_at"])

        # Initialize the binned datetimes dictionary
        binned_datetimes = {}

        # Iterate over all classification datetimes
        for classification_datetime in classification_datetimes:

            # Bin the datetimes
            if(binning_parameter == "Day"):
                day = classification_datetime.date()
                if day in binned_datetimes:
                    binned_datetimes[day].append(classification_datetime)
                else:
                    binned_datetimes[day] = [classification_datetime]
            elif(binning_parameter == "Week"):
                week = classification_datetime.isocalendar()[1]
                if week in binned_datetimes:
                    binned_datetimes[week].append(classification_datetime)
                else:
                    binned_datetimes[week] = [classification_datetime]
            elif(binning_parameter == "Month"):
                month = classification_datetime.month
                if month in binned_datetimes:
                    binned_datetimes[month].append(classification_datetime)
                else:
                    binned_datetimes[month] = [classification_datetime]
            elif(binning_parameter == "Year"):
                year = classification_datetime.year
                if year in binned_datetimes:
                    binned_datetimes[year].append(classification_datetime)
                else:
                    binned_datetimes[year] = [classification_datetime]

        # Convert the binned datetimes to a dictionary of counts
        binned_datetimes = {k: len(v) for k, v in binned_datetimes.items()}

        # Plot the timeline
        if(bar):
            plt.bar(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        else:
            plt.plot(binned_datetimes.keys(), binned_datetimes.values(), **kwargs)
        plt.title("Classification Timeline")
        plt.xlabel(binning_parameter)
        plt.ylabel("Count")
        plt.show()

    def getSubject(self, subject_id):
        """
        Gets the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """

        # Get the subject with the given subject ID in the subject set with the given subject set ID
        return Spout.get_subject(int(subject_id), self.subject_set_id)

    def getSubjectMetadata(self, subject_id):
        """
        Gets the metadata for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata from.
        
        Returns
        -------
        metadata : dict
            The metadata for the subject with the given subject ID.
        """

        # Get the subject with the given subject ID
        if(self.subjects_file is not None):
            subject_dataframe = self.subjects_dataframe[self.subjects_dataframe["subject_id"] == subject_id]
            if(subject_dataframe.empty):
                return None
            else:
                return eval(self.subjects_dataframe[self.subjects_dataframe["subject_id"] == subject_id].iloc[0]["metadata"])
        else:
            subject = self.getSubject(subject_id)

            try:
                # Get the subject's metadata
                subject_metadata = subject.metadata

                # Return the subject's metadata
                return subject_metadata
            except AttributeError:
                # If the subject could not be found, then return None
                return None

    def getSubjectMetadataField(self, subject_id, field_name):
        """
        Gets the metadata field with the given field name for the subject with the given subject ID.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the metadata field from.
        field_name : str
            The name of the metadata field to get.
        
        Returns
        -------
        field_value : str
            The value of the metadata field with the given field name for the subject with the given subject ID.
        """

        # Get the subject's metadata
        subject_metadata = self.getSubjectMetadata(subject_id)

        if(subject_metadata is None):
            return None

        # Get the metadata field with the given field name
        field_value = subject_metadata.get(field_name)

        # Return the metadata field value
        return field_value

    def showSubject(self, subject_id, open_in_browser=False):
        """
        Shows the subject with the given subject ID by opening the WiseView link in the default web browser
        and by returning the WiseView link.
        
        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to show.
        open_in_browser : bool
            Whether to open the subject in the default web browser. Default is False.
        
        Returns
        -------
        subject : panoptes_client.Subject
            The subject with the given subject ID.
        """

        # Get the WiseView link for the subject with the given subject ID
        wise_view_link = self.getSubjectMetadataField(subject_id, "WISEVIEW")

        # Return None if no WiseView link was found
        if(wise_view_link is None):
            print(f"No WiseView link found for subject {subject_id}, so it cannot be shown.")
            return None

        # Remove the WiseView link prefix and suffix
        wise_view_link = wise_view_link.removeprefix("[WiseView](+tab+")
        wise_view_link = wise_view_link.removesuffix(")")

        # Determine whether to open the subject in the default web browser
        if wise_view_link is None:
            print(f"No WiseView link found for subject {subject_id}")
            return None
        else:
            if(open_in_browser):
                webbrowser.open(wise_view_link)

        # Return the WiseView link
        return wise_view_link

    def getSIMBADLink(self, subject_id):
        """
        Gets the SIMBAD link for the subject with the given subject ID.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to get the SIMBAD link for.

        Returns
        -------
        simbad_link : str
            The SIMBAD link for the subject with the given subject ID.
        """

        simbad_link = self.getSubjectMetadataField(subject_id, "SIMBAD")

        if (simbad_link is None):
            print(f"No SIMBAD link found for subject {subject_id}, so it cannot be provided.")
            return None

            # Remove the SIMBAD link prefix and suffix
        simbad_link = simbad_link.removeprefix("[SIMBAD](+tab+")
        simbad_link = simbad_link.removesuffix(")")

        return simbad_link

    def getSimbadQuery(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec, plot=False, separation=None):
        subject_metadata = self.getSubjectMetadata(subject_id)

        RA = subject_metadata["RA"]
        DEC = subject_metadata["DEC"]
        coords = [RA, DEC]

        if(search_type == "Box" or search_type == "Box Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "FOV": FOV}
        elif(search_type == "Cone" or search_type == "Cone Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "radius": radius}
        else:
            raise ValueError(f"Invalid search type: {search_type}. Expected 'Cone', 'Cone Search', 'Box', or 'Box Search'.")

        simbad_searcher = SimbadSearcher(search_parameters)

        result = simbad_searcher.getQuery()

        if(plot):
            simbad_searcher.plotEntries(separation=separation)

        return result

    def getConditionalSimbadQuery(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec, otypes=["BD*", "BD?", "BrownD*", "BrownD?", "BrownD*_Candidate", "PM*"], plot=False, separation=None):
        subject_metadata = self.getSubjectMetadata(subject_id)
        RA = subject_metadata["RA"]
        DEC = subject_metadata["DEC"]
        coords = [RA, DEC]

        # Introduce a buffer to the FOV to more reliably capture high proper motion objects
        extreme_proper_motion = 5 * u.arcsec / u.yr
        current_epoch = float(Time.now().decimalyear) * u.yr
        simbad_epoch = 2000 * u.yr
        time_difference = current_epoch - simbad_epoch
        max_separation = extreme_proper_motion * time_difference
        buffer_FOV = 2 * max_separation
        buffer_radius = max_separation

        if (search_type == "Box" or search_type == "Box Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "FOV": FOV + buffer_FOV}
        elif (search_type == "Cone" or search_type == "Cone Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "radius": radius + buffer_radius}
        else:
            raise ValueError(f"Invalid search type: {search_type}. Expected 'Cone', 'Cone Search', 'Box', or 'Box Search'.")

        simbad_searcher = SimbadSearcher(search_parameters)
        otypes_condition = simbad_searcher.buildConditionalArgument("OTYPES", "==", otypes)
        conditions = [otypes_condition]
        result = simbad_searcher.getConditionalQuery(conditions)

        if(plot):
            simbad_searcher.plotEntries(separation=separation)

        return result

    def sourceExistsInSimbad(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec):
        """
        Determines whether there is a source in Simbad within the provided search parameters of the subject.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        in_simbad : bool
            Whether there is a source in Simbad within the provided search parameters of the subject.
        """

        return len(self.getSimbadQuery(subject_id, search_type=search_type, FOV=FOV, radius=radius)) > 0

    def getGaiaQuery(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec, plot=False, separation=None):
        # Get the subject's metadata
        subject_metadata = self.getSubjectMetadata(subject_id)
        RA = subject_metadata["RA"]
        DEC = subject_metadata["DEC"]
        coords = [RA, DEC]

        if (search_type == "Box" or search_type == "Box Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "FOV": FOV}
        elif (search_type == "Cone" or search_type == "Cone Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "radius": radius}
        else:
            raise ValueError(f"Invalid search type: {search_type}. Expected 'Cone', 'Cone Search', 'Box', or 'Box Search'.")

        gaia_searcher = GaiaSearcher(search_parameters)

        result = gaia_searcher.getQuery()

        if (plot):
            gaia_searcher.plotEntries(separation=separation)

        return result

    def getConditionalGaiaQuery(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec, gaia_pm=100 * u.mas / u.yr, plot=False, separation=None):
        subject_metadata = self.getSubjectMetadata(subject_id)
        RA = subject_metadata["RA"]
        DEC = subject_metadata["DEC"]
        coords = [RA, DEC]

        # Introduce a buffer to the FOV to more reliably capture high proper motion objects
        extreme_proper_motion = 5 * u.arcsec / u.yr
        current_epoch = float(Time.now().decimalyear) * u.yr
        gaia_epoch = 2016 * u.yr
        time_difference = current_epoch - gaia_epoch
        max_separation = extreme_proper_motion * time_difference
        buffer_FOV = 2 * max_separation
        buffer_radius = max_separation

        if (search_type == "Box" or search_type == "Box Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "FOV": FOV + buffer_FOV}
        elif (search_type == "Cone" or search_type == "Cone Search"):
            search_parameters = {"Coordinates": coords, "Type": search_type, "radius": radius + buffer_radius}
        else:
            raise ValueError(
                f"Invalid search type: {search_type}. Expected 'Cone', 'Cone Search', 'Box', or 'Box Search'.")

        gaia_searcher = GaiaSearcher(search_parameters)
        proper_motion_condition = gaia_searcher.buildConditionalArgument("pm", ">=", gaia_pm)
        result = gaia_searcher.getConditionalQuery(proper_motion_condition)

        if (plot):
            gaia_searcher.plotEntries(separation=separation)

        return result

    def sourceExistsInGaia(self, subject_id, search_type="Box Search", FOV=120*u.arcsec, radius=60*u.arcsec):
        """
        Determines whether there is a source in Gaia within the provided search parameters of the subject.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check around.

        Returns
        -------
        in_gaia : bool
            Whether there is a source in Gaia within the provided search parameters of the subject.
        """

        return len(self.getGaiaQuery(subject_id, search_type=search_type, FOV=FOV, radius=radius)) > 0

    def subjectExists(self, subject_id):
        """
        Determines whether the subject exists.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        subject_exists : bool
            Whether the subject exists.
        """

        # Get the subject's metadata
        metadata = self.getSubjectMetadata(subject_id)

        # Return whether the subject exists
        return metadata is not None

    @staticmethod
    def bitmaskToType(bitmask):
        """
        Converts a bitmask to a subject type.
        
        Parameters
        ----------
        bitmask : int, str
            The bitmask value to convert to a subject type.
        
        Returns
        -------
        bitmask_type : str
            The subject type associated with the bitmask value.
        """

        # Convert the bitmask to an integer
        try:
            bitmask = int(bitmask)
        except ValueError:
            raise ValueError("bitmask must be an integer or a string that can be converted to an integer.")

        # Initialize the bitmask dictionary
        bitmask_dict = {2**0: "SMDET Candidate", 2**1: "Blank", 2**2: "Known Brown Dwarf", 2**3: "Quasar", 2**4: "Random Sky Location", 2**5: "White Dwarf"}

        # Return the bitmask type associated with the bitmask value
        return bitmask_dict.get(bitmask, None)

    def getSubjectType(self, subject_id):
        # Get the bitmask for the subject
        bitmask = self.getSubjectMetadataField(subject_id, "#BITMASK")

        if(bitmask is None):
            print(f"Subject {subject_id} does not have a bitmask, so its type cannot be determined.")
            return None

        # Convert the bitmask to a subject type
        bitmask_type = self.bitmaskToType(bitmask)

        return bitmask_type

    def isAcceptableCandidate(self, subject_id, acceptance_ratio):
        subject_type = self.getSubjectType(subject_id)
        subject_classifications = self.getSubjectClassifications(subject_id)

        # Count the number of successful classifications for each of the bitmask types
        total_classifications = subject_classifications["yes"] + subject_classifications["no"]
        movement_ratio = subject_classifications["yes"] / total_classifications
        non_movement_ratio = subject_classifications["no"] / total_classifications

        if (subject_type == "SMDET Candidate"):
            return movement_ratio > acceptance_ratio, subject_classifications
        else:
            return False, subject_classifications

    def searchSubjectFieldOfView(self, subject_id):
        """
        Determines whether the subject's FOV search area has any known objects in it.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        in_known_databases : bool
            Whether the subject's FOV search area has any known objects in it.
        """
        FOV = 120 * u.arcsec

        database_check_dict = {"Simbad": self.sourceExistsInSimbad(subject_id, search_type="Box Search", FOV=FOV), "Gaia": self.sourceExistsInGaia(subject_id, search_type="Box Search", FOV=FOV)}

        # For each database, check if the subject's FOV search area has any known objects in it
        if(any(database_check_dict.values())):
            return True, database_check_dict
        else:
            return False, database_check_dict

    def checkSubjectFieldOfView(self, subject_id, otypes=["BD*", "BD?", "BrownD*", "BrownD?", "BrownD*_Candidate", "PM*"], gaia_pm=100 * u.mas / u.yr):
        """
        Determines whether the subject's FOV search area has any known objects in it given the distance threshold
        and default otypes conditions.

        Parameters
        ----------
        subject_id : str, int
            The ID of the subject to check.

        Returns
        -------
        in_known_databases : bool
            Whether the subject's FOV search area has any known objects in it.
        """

        simbad_query = self.getConditionalSimbadQuery(subject_id, search_type="Box Search", FOV=120*u.arcsec, otypes=otypes)
        gaia_query = self.getConditionalGaiaQuery(subject_id, search_type="Box Search", FOV=120*u.arcsec, gaia_pm=gaia_pm)

        database_query_dict = {"SIMBAD": simbad_query, "Gaia": gaia_query}
        database_check_dict = {}
        # Check each query to determine if it is empty or None
        for database, query in database_query_dict.items():
            if(query is None):
                database_check_dict[database] = False
            else:
                database_check_dict[database] = len(query) > 0

        return database_check_dict, database_query_dict

    def determineAcceptanceCounts(self, acceptance_ratio):
        """
        Determines the acceptance count of each subject type.
        
        Returns
        -------
        success_count_dict : dict
            A dictionary containing the acceptance count of each subject type,
            if there is a known correct answer.

        Notes
        -----
        The success count is the number of subjects of a given type that have been classified correctly.
        This is only applicable to subjects that have a known correct answer, such as known brown dwarfs, quasars,
        and random sky locations.
        """

        # Get the subject IDs
        subject_ids = self.getSubjectIDs()

        # Initialize the success count dictionary
        success_count_dict = {}

        # Iterate through the subject IDs
        for subject_id in subject_ids:

            subject_type = self.getSubjectType(subject_id)

            # If the bitmask type is None, continue
            if subject_type is None:
                continue

            # If the bitmask type is not in the success count dictionary, add it
            if subject_type not in success_count_dict:
                success_count_dict[subject_type] = {"total": 0, "success": 0}

            # Increment the total count for the bitmask type
            success_count_dict[subject_type]["total"] += 1

            # Get the subject classifications
            subject_classifications = self.getSubjectClassifications(subject_id)

            # Count the number of successful classifications for each of the bitmask types
            total_classifications = subject_classifications["yes"] + subject_classifications["no"]
            movement_ratio = subject_classifications["yes"] / total_classifications
            non_movement_ratio = subject_classifications["no"] / total_classifications

            if(subject_type == "Known Brown Dwarf"):
                if(movement_ratio >= acceptance_ratio):
                    success_count_dict[subject_type]["success"] += 1
            elif(subject_type == "Quasar"):
                if(non_movement_ratio >= acceptance_ratio):
                    success_count_dict[subject_type]["success"] += 1
            elif(subject_type == "White Dwarf"):
                success_count_dict[subject_type]["success"] = None
            elif(subject_type == "SMDET Candidate"):
                success_count_dict[subject_type]["success"] = None
            elif(subject_type == "Random Sky Location"):
                if (non_movement_ratio >= acceptance_ratio):
                    success_count_dict[subject_type]["success"] += 1

        # Return the success count dictionary
        return success_count_dict

    @staticmethod
    def combineSubjectDataframes(subject_dataframe_list):
        """
        Combines a list of subject dataframes into a single subject dataframe.

        Parameters
        ----------
        subject_dataframe_list : list
            A list of subject dataframes to combine.

        Returns
        -------
        combined_subject_dataframe : pandas.DataFrame
            The combined subject dataframe.
        """

        if(len(subject_dataframe_list) == 0):
            return pd.DataFrame()

        # Combine the subject dataframes
        combined_subject_dataframe = pd.concat(subject_dataframe_list, ignore_index=True)

        # Drop any duplicate subjects
        combined_subject_dataframe.drop_duplicates(subset=["subject_id"], inplace=True)

        # Return the combined subject dataframe
        return combined_subject_dataframe

    @staticmethod
    def saveSubjectDataframe(subject_dataframe, filename):
        """
        Saves the subject dataframe to a CSV file.

        Parameters
        ----------
        subject_dataframe : pandas.DataFrame
            The subject dataframe to save.
        filename : str
            The name of the file to save the subject dataframe to.
        """

        # Save the subject dataframe to a CSV file
        subject_dataframe.to_csv(filename, index=False)

    @staticmethod
    def loadSubjectDataframe(filename):
        """
        Loads the subject dataframe from a CSV file.

        Parameters
        ----------
        filename : str
            The name of the file to load the subject dataframe from.

        Returns
        -------
        subject_dataframe : pandas.DataFrame
            The subject dataframe loaded from the CSV file.
        """

        # Load the subject dataframe from a CSV file
        subject_dataframe = pd.read_csv(filename)

        # Return the subject dataframe
        return subject_dataframe

    @staticmethod
    def plotSubjectDataframe(subject_dataframe):
        # create a temporary csv file of the subject dataframe
        subject_dataframe.to_csv("temp.csv", index=False)
        subject_csv_plotter = SubjectCSVPlotter("temp.csv")
        subject_csv_plotter.plot()
        os.remove("temp.csv")


