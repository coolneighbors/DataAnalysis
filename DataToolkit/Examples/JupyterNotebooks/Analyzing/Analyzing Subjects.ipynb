{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa606bc",
   "metadata": {},
   "source": [
    "# Analyzing Subjects:\n",
    "<break> </break>\n",
    "<font size=4>\n",
    "The Analyzer, along with the classifier class, provide lots of functionality towards analyzing the Cool Neighbors classification data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417ecae",
   "metadata": {},
   "source": [
    "## Aggregating the Classifications\n",
    "\n",
    "The Analyzer class object requires the extraction and reduction files produced via the Aggregator class. See the Aggregating example for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e062a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command:  panoptes_aggregation config C:\\Users\\Austin\\Documents\\GitHub\\DataToolkit\\DataToolkit\\Examples\\JupyterNotebooks\\Analyzing\\backyard-worlds-cool-neighbors-workflows.csv 24299 -d C:\\Users\\Austin\\Documents\\GitHub\\DataToolkit\\DataToolkit\\Examples\\JupyterNotebooks\\Analyzing\\Config -v 1.6\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregated files already exist, skipping aggregation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[43maggregator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregateWorkflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkflow_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkflow_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\site-packages\\DataToolkit\\Aggregator.py:99\u001b[0m, in \u001b[0;36mAggregator.aggregateWorkflow\u001b[1;34m(self, workflow_id, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03mClassifies a workflow using the Panoptes aggregation client by generating config files,\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mextracted files, and reduction files.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        Optional arguments to be passed to the config command.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Generate config files, extracted files, and reduction files\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig(workflow_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\site-packages\\DataToolkit\\Aggregator.py:161\u001b[0m, in \u001b[0;36mAggregator.config\u001b[1;34m(self, workflow_id, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Run the command and capture the output\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommand: \u001b[39m\u001b[38;5;124m\"\u001b[39m, command_str)\n\u001b[1;32m--> 161\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Decode the output assuming it's in UTF-8 encoding\u001b[39;00m\n\u001b[0;32m    164\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DataToolkit\\lib\\subprocess.py:1436\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1436\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1452\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1453\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from DataToolkit.Aggregator import Aggregator\n",
    "# For more details about Aggregating, see the Aggregating example.\n",
    "\n",
    "# This is the workflow ID and version for the Backyard Worlds: Cool Neighbors project's Launch-0 workflow.\n",
    "workflow_id = 24299\n",
    "version = 1.6\n",
    "\n",
    "# Default names for the CSV files that are exported via Zooniverse's data exports tab.\n",
    "classifications_csv = \"backyard-worlds-cool-neighbors-classifications.csv\"\n",
    "workflows_csv = \"backyard-worlds-cool-neighbors-workflows.csv\"\n",
    "config_directory = \"Config\"\n",
    "extractions_directory = \"Extractions\"\n",
    "reductions_directory = \"Reductions\"\n",
    "\n",
    "# Check whether the aggregated files already exist for this workflow and version\n",
    "aggregator = Aggregator(classifications_csv_filename=classifications_csv, workflow_csv_filename=workflows_csv, config_directory=config_directory, extractions_directory=extractions_directory, reductions_directory=reductions_directory)\n",
    "\n",
    "if(os.path.exists(\"{}/question_extractor_workflow_{}_V{}.csv\".format(aggregator.extractions_directory, workflow_id, version)) and os.path.exists(\"{}/question_reducer_workflow_{}_V{}.csv\".format(aggregator.reductions_directory, workflow_id, version))):\n",
    "    print(\"Aggregated files already exist, skipping aggregation.\")\n",
    "else:\n",
    "    aggregator.aggregateWorkflow(workflow_id=workflow_id, v=version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00a8ef",
   "metadata": {},
   "source": [
    "## Getting Subjects from Zooniverse\n",
    "\n",
    "In order to access subjects, once you've logged in, you can either request all subjects from a particular project, from a particular subject set, or you can request subjects directly via their subject id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the project id and subject set id you wish to get subjects from.\n",
    "# By default, the project ID and subject set ID are saved to the filenames \"project_id.pickle\" and \"subject_set_id.pickle\" \n",
    "# and save is set to True.\n",
    "project_id, subject_set_id = Spout.requestZooniverseIDs(filenames=[\"project_id.pickle\", \"subject_set_id.pickle\"], save=True)\n",
    "\n",
    "print(\"Warning: This will take a long time to run if there are a lot of subjects in the project.\")\n",
    "\n",
    "# Get all subjects in the project.\n",
    "project_subjects = Spout.get_subjects_from_project(project_id, only_orphans=False)\n",
    "print(f\"Number of subjects in the project: {len(project_subjects)}\\n\")\n",
    "\n",
    "# Get all orphaned subjects in the project.\n",
    "orphaned_project_subjects = Spout.get_subjects_from_project(project_id, only_orphans=True)\n",
    "print(f\"Number of orphaned subjects in the project: {len(orphaned_project_subjects)}\\n\")\n",
    "\n",
    "# Get all subjects in the subject set.\n",
    "subject_set_subjects = Spout.get_subjects_from_project(project_id, subject_set_id, only_orphans=False)\n",
    "print(f\"Number of subjects in the subject set: {len(subject_set_subjects)}\\n\")\n",
    "\n",
    "# Get a single subject by its ID.\n",
    "subject_id = None\n",
    "if(subject_id is not None):\n",
    "    single_subject = Spout.get_subject(subject_id)\n",
    "    print(f\"Single subject: {single_subject}\\n\")\n",
    "\n",
    "# With the list of subjects, or individual subjects, you can do whatever you want with them. For example, you can find a subset of\n",
    "# subjects that meet a certain criteria using the SubjectDiscriminator class (see DataToolkit\\Discriminator.py).\n",
    "\n",
    "# Additionally, you can get a user object from their ID or username:\n",
    "user_id = \"austinh2001\"\n",
    "if(user_id is not None):\n",
    "    user = Spout.get_user(user_id)\n",
    "    print(f\"User: {user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3162ed0",
   "metadata": {},
   "source": [
    "## Modifying Subjects\n",
    "\n",
    "In order to avoid accidental modifications to subjects, the modification functions will be commented out. \n",
    "If you would like to use them, please uncomment them. Be sure to verify you are modifying the correct subjects before uncommenting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "\n",
    "# Remove subjects from a subject set:\n",
    "\"\"\"\n",
    "Spout.remove_subjects(project_id, subject_set_id, subjects)\n",
    "\"\"\"\n",
    "\n",
    "# Delete subjects from Zooniverse:\n",
    "\"\"\"\n",
    "Spout.delete_subjects(subjects)\n",
    "\"\"\"\n",
    "\n",
    "# Modify subject metadata field names:\n",
    "\"\"\"\n",
    "Spout.modify_subject_metadata_field_name(subjects, \"Ecliptic Coordinates\", \"#Ecliptic Coordinates\")\n",
    "\"\"\"\n",
    "\n",
    "# Modify subject metadata field values:\n",
    "\"\"\"\n",
    "Spout.modify_subject_metadata_field_value(subjects, \"FOV\", \"~120.0 x ~120.0 arcseconds\")\n",
    "\"\"\"\n",
    "\n",
    "# Check if a subject has images:\n",
    "\"\"\"\n",
    "for subject in subjects:\n",
    "    print(f\"Subject {subject.id} has images: {Spout.subject_has_images(subject)}\")\n",
    "\"\"\"\n",
    "\n",
    "# Check if a subject has metadata:\n",
    "\"\"\"\n",
    "for subject in subjects:\n",
    "    print(f\"Subject {subject.id} has metadata: {Spout.subject_has_metadata(subject)}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataToolkit",
   "language": "python",
   "name": "datatoolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
