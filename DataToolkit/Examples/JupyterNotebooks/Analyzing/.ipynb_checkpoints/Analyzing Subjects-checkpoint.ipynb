{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa606bc",
   "metadata": {},
   "source": [
    "# Analyzing Subjects:\n",
    "<break> </break>\n",
    "<font size=4>\n",
    "The Analyzer, along with the classifier class, provide lots of functionality towards analyzing the Cool Neighbors classification data.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417ecae",
   "metadata": {},
   "source": [
    "## Aggregating the Classifications\n",
    "\n",
    "The Analyzer class object requires the extraction and reduction files produced via the Aggregator class. See the Aggregating example for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e062a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated files already exist, skipping aggregation.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from DataToolkit.Aggregator import Aggregator\n",
    "\n",
    "# For more details about Aggregating, see the Aggregating example.\n",
    "\n",
    "# This is the workflow ID and version for the Backyard Worlds: Cool Neighbors project's Launch-0 workflow.\n",
    "workflow_id = 24299\n",
    "version = 1.6\n",
    "\n",
    "# Default names for the CSV files that are exported via Zooniverse's data exports tab.\n",
    "classifications_csv = \"backyard-worlds-cool-neighbors-classifications.csv\"\n",
    "workflows_csv = \"backyard-worlds-cool-neighbors-workflows.csv\"\n",
    "config_directory = \"Config\"\n",
    "extractions_directory = \"Extractions\"\n",
    "reductions_directory = \"Reductions\"\n",
    "\n",
    "# Check whether the aggregated files already exist for this workflow and version\n",
    "aggregator = Aggregator(classifications_csv_filename=classifications_csv, workflow_csv_filename=workflows_csv, config_directory=config_directory, extractions_directory=extractions_directory, reductions_directory=reductions_directory)\n",
    "\n",
    "if(os.path.exists(\"{}/question_extractor_workflow_{}_V{}.csv\".format(aggregator.extractions_directory, workflow_id, version)) and os.path.exists(\"{}/question_reducer_workflow_{}_V{}.csv\".format(aggregator.reductions_directory, workflow_id, version))):\n",
    "    print(\"Aggregated files already exist, skipping aggregation.\")\n",
    "else:\n",
    "    print(\"Aggregating...\")\n",
    "    aggregator.aggregateWorkflow(workflow_id=workflow_id, v=version)\n",
    "    print(\"Aggregation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00a8ef",
   "metadata": {},
   "source": [
    "## Creating the Analyzer\n",
    "The analyzer will be your all-inclusive tool for working with the panoptes_aggregation results, generated via the Aggregator.\n",
    "\n",
    "In addition to the analzyer's functionality, it also has a Classifier instance within it which itself has functionality regarding the accuracies of user's and weighting classifications by user accuracy in the candidate selection process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395bdfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Analyzer object from 'analyzer.pickle'\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from DataToolkit.Analyzer import Analyzer\n",
    "\n",
    "# Provide the filepaths of the aggregated files\n",
    "extracted_file = \"Extractions/question_extractor_workflow_24299_V1.6.csv\"\n",
    "reduced_file = \"Reductions/question_reducer_workflow_24299_V1.6.csv\"\n",
    "\n",
    "# Subject file is optional but highly recommended, as it allows for you to work with subjects offline\n",
    "# and is generally faster than the online version.\n",
    "subject_file = \"backyard-worlds-cool-neighbors-subjects.csv\"\n",
    "if(subject_file is not None):\n",
    "    # If an offline analyzer has already been created and saved, you can load it instead of creating it again. You cannot\n",
    "    # load an online analyzer.\n",
    "    if (os.path.exists(\"analyzer.pickle\")):\n",
    "        print(\"Loading Analyzer...\")\n",
    "        analyzer = Analyzer.load()\n",
    "    else:\n",
    "        print(\"Creating Analyzer...\")\n",
    "        # Providing a subjects_file will default the analyzer to being offline.\n",
    "        analyzer = Analyzer(extracted_file, reduced_file, subject_file)\n",
    "else:\n",
    "    # Not providing a subjects_file will default the analyzer to being online.\n",
    "    analyzer = Analyzer(extracted_file, reduced_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3162ed0",
   "metadata": {},
   "source": [
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06a006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataToolkit",
   "language": "python",
   "name": "datatoolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
